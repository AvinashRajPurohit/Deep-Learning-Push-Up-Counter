{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Computer Vision push ups counter\n",
    "\n",
    "In this project I have combined two techniques to construct a simple computer vision technique to count the number of push ups, pull ups or squats from a video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the validation and train data generators, from the directories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 376 images belonging to 3 classes.\n",
      "Found 84 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import distutils\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    './data/train',\n",
    "    target_size=(64, 64),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    seed=42)\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    './data/validation',\n",
    "    target_size=(64, 64),\n",
    "    batch_size=1,\n",
    "    class_mode='categorical')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  model = tf.keras.models.Sequential()\n",
    "  model.add(tf.keras.Input(shape=(64,64,3)))\n",
    "  #model.add(tf.keras.layers.BatchNormalization())\n",
    "  model.add(tf.keras.layers.Conv2D(6, (3, 3), padding='same', activation='relu'))\n",
    "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "  \n",
    "  model.add(tf.keras.layers.Conv2D(16, (3,3), padding='same', activation='relu'))\n",
    "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "  #model.add(tf.keras.layers.BatchNormalization())\n",
    "  model.add(tf.keras.layers.Conv2D(32, (3,3), padding='same', activation='relu'))\n",
    "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "\n",
    "  #model.add(tf.keras.layers.BatchNormalization())\n",
    "  model.add(tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))  \n",
    "\n",
    "  model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "  model.add(tf.keras.layers.Flatten())\n",
    "  model.add(tf.keras.layers.Dense(512))\n",
    "  model.add(tf.keras.layers.Activation('relu'))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "  model.add(tf.keras.layers.Dense(128))\n",
    "  model.add(tf.keras.layers.Activation('relu'))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "  model.add(tf.keras.layers.Dense(64))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "  model.add(tf.keras.layers.Dense(3))\n",
    "  model.add(tf.keras.layers.Activation('softmax'))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the model and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24/24 [==============================] - 13s 536ms/step - loss: 0.9943 - categorical_accuracy: 0.4016 - val_loss: 0.7613 - val_categorical_accuracy: 0.5238\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 13s 543ms/step - loss: 0.8253 - categorical_accuracy: 0.6995 - val_loss: 0.7210 - val_categorical_accuracy: 0.7500\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 13s 550ms/step - loss: 0.6235 - categorical_accuracy: 0.7766 - val_loss: 0.6164 - val_categorical_accuracy: 0.8095\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 14s 566ms/step - loss: 0.5352 - categorical_accuracy: 0.8059 - val_loss: 0.4083 - val_categorical_accuracy: 0.8333\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 13s 523ms/step - loss: 0.5674 - categorical_accuracy: 0.7606 - val_loss: 0.4435 - val_categorical_accuracy: 0.8095\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 12s 511ms/step - loss: 0.4443 - categorical_accuracy: 0.8138 - val_loss: 0.3677 - val_categorical_accuracy: 0.8690\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 12s 503ms/step - loss: 0.3559 - categorical_accuracy: 0.8830 - val_loss: 0.3676 - val_categorical_accuracy: 0.8929\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 12s 481ms/step - loss: 0.3270 - categorical_accuracy: 0.8617 - val_loss: 0.3359 - val_categorical_accuracy: 0.9048\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 12s 499ms/step - loss: 0.3460 - categorical_accuracy: 0.8936 - val_loss: 0.2830 - val_categorical_accuracy: 0.9286\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 12s 487ms/step - loss: 0.3548 - categorical_accuracy: 0.8644 - val_loss: 0.3306 - val_categorical_accuracy: 0.8929\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.compile(\n",
    "      optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "      loss='categorical_crossentropy',\n",
    "      metrics=['categorical_accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_freq=1\n",
    ")\n",
    "\n",
    "model.save('model.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and generating a new video with the repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "cap = cv2.VideoCapture(\"test_video.mov\")\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
    "out = cv2.VideoWriter('output_count.avi',fourcc, 20.0,(int(cap.get(3)),int(cap.get(4))))\n",
    "\n",
    "ret, frame1 = cap.read()\n",
    "prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "hsv = np.zeros_like(frame1)\n",
    "hsv[...,1] = 255\n",
    "i= 0\n",
    "prediction_str = \"\"\n",
    "repetitions = 0\n",
    "up = 0\n",
    "down = 0\n",
    "no_move = 0\n",
    "current_move = 0\n",
    "initial = -1\n",
    "while(cap.isOpened()):\n",
    "    i+=1\n",
    "    \n",
    "    ret, frame2 = cap.read()\n",
    "    if not(ret): break\n",
    "    next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "    \n",
    "\n",
    "    mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "    hsv[...,0] = ang*180/np.pi/2\n",
    "    hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "    rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    image = cv2.resize(rgb, (64, 64))\n",
    "    image = image.reshape((1,) + image.shape)\n",
    "    image = image/255.0\n",
    "    prediction = np.argmax(model.predict(image), axis=-1)[0]\n",
    "    \n",
    "    if prediction == 0:\n",
    "        down +=1 \n",
    "        if down == 3:\n",
    "          if initial == -1:\n",
    "            initial = 0\n",
    "          if current_move == 2:\n",
    "            repetitions+=1\n",
    "          current_move = 0\n",
    "        elif down > 0:\n",
    "          up = 0\n",
    "          no_move = 0\n",
    "    elif prediction == 2:\n",
    "        up += 1\n",
    "        if up == 3 and initial != -1:\n",
    "          current_move = 2\n",
    "        elif up > 1:\n",
    "          down = 0 \n",
    "          no_move = 0\n",
    "    else:\n",
    "        no_move += 1\n",
    "        if no_move == 15:\n",
    "          current_move = 1\n",
    "        elif no_move > 10:\n",
    "          up = 0\n",
    "          down = 0 \n",
    "    font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    bottomLeftCornerOfText = (10,400)\n",
    "    fontScale              = 1\n",
    "    fontColor              = (255,255,255)\n",
    "    lineType               = 5\n",
    "    cv2.putText(frame2, \"Repetitions: \"+ str(repetitions),bottomLeftCornerOfText,font, fontScale,fontColor,lineType)\n",
    "    out.write(frame2)\n",
    "    prvs = next\n",
    "\n",
    "print(\"Video Generated\")\n",
    "out.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
